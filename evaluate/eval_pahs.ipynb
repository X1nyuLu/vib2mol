{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Retrieval (given functional groups, retrieval the situated sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/MolTokenizer')\n",
    "\n",
    "db = lmdb.open('../datasets/vibench/pahs/pahs_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "from utils.base import seed_everything\n",
    "\n",
    "seed_everything(624)\n",
    "device = 'cpu'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt = torch.load('../checkpoints/pahs/raman-kekule_smiles/vib2mol_phase.pth', \n",
    "                  map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_pattern_dict = {\n",
    "1: \n",
    "    {\n",
    "    '(.*?)C1=CC=CC=C1': '1', \n",
    "    '(.*?)C1=C\\((.*?)\\)C=CC=C1': '1,2',\n",
    "    '(.*?)C1=CC=CC\\((.*?)\\)=C1': '1,3',\n",
    "    '(.*?)C1=CC\\((.*?)\\)=CC=C1': '1,3',\n",
    "    '(.*?)C1=CC=C\\((.*?)\\)C=C1': '1,4',\n",
    "    },\n",
    "2:\n",
    "    {\n",
    "    '(.*?)C1=CC2=CC=CC2=CC=CC=C1': '1',\n",
    "    '(.*?)C1=C2C=CC=CC2=CC=CC=C1': '1',  \n",
    "    '(.*?)C1=CC=C2C=CC=CC2=C1(.*?)\\Z': '1,2',\n",
    "    '(.*?)C1=C\\((.*?)\\)C=CC2=CC=CC=C12': '1,2',\n",
    "    '(.*?)C1=CC=CC2=C\\((.*?)\\)C=CC=C12': '1,5',\n",
    "    '(.*?)C1=CC=CC2=CC=CC\\((.*?)\\)=C12': '1,8',\n",
    "    '(.*?)C1=CC=C2C=C\\((.*?)\\)C=CC2=C1': '2,6',\n",
    "    '(.*?)C1=CC=C2C=CC\\((.*?)\\)=CC2=C1': '2,7',\n",
    "    },\n",
    "3:\n",
    "    {'(.*?)C1=CC=C2C=C3C=CC=CC3=CC2=C1(.*?)\\Z': '1,2',\n",
    "    '(.*?)C1=C\\((.*?)\\)C=CC2=CC3=CC=CC=C3C=C12': '1,2',\n",
    "    '(.*?)C1=C\\((.*?)\\)C=C2C=C3C=CC=CC3=CC2=C1': '2,3',\n",
    "    '(.*?)C1=CC2=CC3=CC=CC=C3C=C2C=C1(.*?)\\Z': '2,3',\n",
    "    '(.*?)C1=CC=C2C=C3C=C\\((.*?)\\)C=CC3=CC2=C1': '2,6'\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pattern_dict = {\n",
    "1: \n",
    "    {\n",
    "    '(.*?)C1=C\\((.*?)\\)C=CC=C1': '1,2',\n",
    "    '(.*?)C1=CC=CC\\((.*?)\\)=C1': '1,3',\n",
    "    '(.*?)C1=CC=C\\((.*?)\\)C=C1': '1,4',\n",
    "    },\n",
    "2:\n",
    "    {\n",
    "    '(.*?)C1=CC=C2C=CC=CC2=C1(.*?)\\Z': '1,2',\n",
    "    '(.*?)C1=CC=CC2=C\\((.*?)\\)C=CC=C12': '1,5',\n",
    "    '(.*?)C1=CC=CC2=CC=CC\\((.*?)\\)=C12': '1,8',\n",
    "    '(.*?)C1=CC=C2C=C\\((.*?)\\)C=CC2=C1': '2,6',\n",
    "    '(.*?)C1=CC=C2C=CC\\((.*?)\\)=CC2=C1': '2,7',\n",
    "    },\n",
    "3:\n",
    "    {'(.*?)C1=CC=C2C=C3C=CC=CC3=CC2=C1(.*?)\\Z': '1,2',\n",
    "    '(.*?)C1=CC2=CC3=CC=CC=C3C=C2C=C1(.*?)\\Z': '2,3',\n",
    "    '(.*?)C1=CC=C2C=C3C=C\\((.*?)\\)C=CC3=CC2=C1': '2,6'\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 51245.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from tqdm import trange, tqdm\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def generate_candidate_list(smiles):\n",
    "    correct = False\n",
    "    if 'C3' in smiles:\n",
    "        ring_count = 3\n",
    "    elif 'C2' in smiles:\n",
    "        ring_count = 2\n",
    "    else:\n",
    "        ring_count = 1\n",
    "        \n",
    "    candidate_smiles_list = []\n",
    "    site_list = []\n",
    "\n",
    "    for k, v in retrieval_pattern_dict[ring_count].items():\n",
    "        tmp = re.findall(k, smiles)  \n",
    "        if len(tmp) != 0:  \n",
    "            correct = True\n",
    "            sub1 = tmp[0][0]\n",
    "            sub2 = tmp[0][1]\n",
    "            tgt_v = v\n",
    "            break\n",
    "        \n",
    "    for k, v in generate_pattern_dict[ring_count].items():\n",
    "        if tgt_v == '1' or v == '1' or v == tgt_v:\n",
    "            continue\n",
    "        backbone = re.sub(r'\\(\\.\\*\\?\\)', 'PLACEHOLDER', k)\n",
    "        backbone = backbone.replace(r'\\(', '(').replace(r'\\)', ')')\n",
    "        \n",
    "        candidate_smiles = backbone.replace('(PLACEHOLDER)', f\"({sub2})\")\n",
    "        candidate_smiles = candidate_smiles.replace(r'PLACEHOLDER\\Z', f\"{sub2}\")\n",
    "        candidate_smiles = candidate_smiles.replace('PLACEHOLDER', sub1)\n",
    "\n",
    "        candidate_smiles_list.append(candidate_smiles)\n",
    "\n",
    "        site_list += [v]\n",
    "    if not correct:  \n",
    "        raise ValueError(\"Re pattern Error\")  \n",
    "    else:\n",
    "        candidate_smiles_list = [smiles] + candidate_smiles_list\n",
    "        site_list = [tgt_v] + site_list\n",
    "        return candidate_smiles_list, site_list\n",
    "\n",
    "\n",
    "batch_id = []\n",
    "target_spectra_list = []\n",
    "candidate_smiles_list = []\n",
    "candidate_site_list = []\n",
    "\n",
    "for i in trange(len(test_df)):\n",
    "\n",
    "    target_smiles = test_df['kekule_smiles'].iloc[i]\n",
    "    target_spectra = test_df['raman'].iloc[i]\n",
    "    try:\n",
    "        tmp_smiles_list, tmp_site_list = generate_candidate_list(target_smiles)\n",
    "    except Exception:\n",
    "        continue\n",
    "    else:\n",
    "        candidate_smiles_list.append(tmp_smiles_list)\n",
    "        candidate_site_list.append(tmp_site_list)\n",
    "        target_spectra_list.append([target_spectra] * len(tmp_smiles_list))\n",
    "        batch_id.extend([i] * len(tmp_smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_smiles_list = [item[0] for item in candidate_smiles_list]\n",
    "candidate_smiles_list = [subitem for item in candidate_smiles_list for subitem in item]\n",
    "target_spectra_list = [subitem for item in target_spectra_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 421/421 [01:31<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # try:\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "        # except Exception:\n",
    "        #     print(idx, len(self.tgt_spectra), len(self.pred_smiles))\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # try:\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "        # except Exception:\n",
    "        #     print(batch)\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(target_spectra_list, candidate_smiles_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.99535\n",
      "top-3:\t\t1.00000\n",
      "top-5:\t\t1.00000\n",
      "top-10:\t\t1.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.991379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top_1  top_3  top_5  top_10\n",
       "ring_count                                \n",
       "1           0.995745    1.0    1.0     1.0\n",
       "2           0.997455    1.0    1.0     1.0\n",
       "3           0.991379    1.0    1.0     1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_ring_count(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    Chem.GetSymmSSSR(mol)  \n",
    "    return mol.GetRingInfo().NumRings()\n",
    "    \n",
    "res = {}\n",
    "valid_sim_list = np.array(valid_sim_list)\n",
    "batch_id = np.array(batch_id)\n",
    "for i, bid in enumerate(set(batch_id)):\n",
    "    tmp_sim_list = valid_sim_list[batch_id == bid]\n",
    "    tmp_smiles_list = np.array(candidate_smiles_list)[batch_id == bid]\n",
    "    tmp_site_list = np.array(candidate_site_list[i])\n",
    "    if len(tmp_site_list) < 2:\n",
    "        continue\n",
    "    res[i] = {'sim':tmp_sim_list[np.argsort(-tmp_sim_list)], \n",
    "              'smiles':tmp_smiles_list[np.argsort(-tmp_sim_list)].tolist(),\n",
    "              'target_smiles':tgt_smiles_list[i],\n",
    "              'sites':tmp_site_list[np.argsort(-tmp_sim_list)],\n",
    "              }\n",
    "\n",
    "df_cl = pd.DataFrame(res).T\n",
    "df_cl['ring_count'] = df_cl['target_smiles'].apply(lambda x: get_ring_count(x))\n",
    "df_cl['top_1'] = df_cl.apply(lambda row: check_beam_mols(row['smiles'][:1], row['target_smiles']), axis=1)\n",
    "df_cl['top_3'] = df_cl.apply(lambda row: check_beam_mols(row['smiles'][:3], row['target_smiles']), axis=1)\n",
    "df_cl['top_5'] = df_cl.apply(lambda row: check_beam_mols(row['smiles'][:5], row['target_smiles']), axis=1)\n",
    "df_cl['top_10'] = df_cl.apply(lambda row: check_beam_mols(row['smiles'][:10], row['target_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df_cl.top_1.mean():.5f}\\ntop-3:\\t\\t{df_cl.top_3.mean():.5f}\\ntop-5:\\t\\t{df_cl.top_5.mean():.5f}\\ntop-10:\\t\\t{df_cl.top_10.mean():.5f}')\n",
    "df_cl.groupby('ring_count').mean('correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MLM (give situated sites, predict the functional groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_dict = {\n",
    " '(.*?)C1=CC=CC=C1': '1',\n",
    " '(.*?)C1=CC2=CC=CC2=CC=CC=C1': '1',\n",
    " '(.*?)C1=C2C=CC=CC2=CC=CC=C1':'1',  \n",
    " '(.*?)C1=C\\((.*?)\\)C=CC=C1': '1,2',\n",
    " '(.*?)C1=CC=CC\\((.*?)\\)=C1': '1,3',\n",
    " '(.*?)C1=CC\\((.*?)\\)=CC=C1': '1,3',\n",
    " '(.*?)C1=CC=C\\((.*?)\\)C=C1': '1,4',\n",
    " '(.*?)C1=CC=C2C=CC=CC2=C1(.*?)\\Z': '1,2',\n",
    " '(.*?)C1=C\\((.*?)\\)C=CC2=CC=CC=C12': '1,2',\n",
    " '(.*?)C1=CC=CC2=C\\((.*?)\\)C=CC=C12': '1,5',\n",
    " '(.*?)C1=CC=CC2=CC=CC\\((.*?)\\)=C12': '1,8',\n",
    " '(.*?)C1=CC=C2C=C\\((.*?)\\)C=CC2=C1': '2,6',\n",
    " '(.*?)C1=CC=C2C=CC\\((.*?)\\)=CC2=C1': '2,7',\n",
    " '(.*?)C1=CC=C2C=C3C=CC=CC3=CC2=C1(.*?)\\Z': '1,2',\n",
    " '(.*?)C1=C\\((.*?)\\)C=CC2=CC3=CC=CC=C3C=C12': '1,2',\n",
    " '(.*?)C1=C\\((.*?)\\)C=C2C=C3C=CC=CC3=CC2=C1': '2,3',\n",
    " '(.*?)C1=CC2=CC3=CC=CC=C3C=C2C=C1(.*?)\\Z': '2,3',\n",
    " '(.*?)C1=CC=C2C=C3C=C\\((.*?)\\)C=CC3=CC2=C1': '2,6'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 6502.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(860, 860, 860)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "from tqdm import trange, tqdm\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def generate_masked_list(smiles, mode='double'):\n",
    "    correct = False\n",
    "    masked_smiles_list = []\n",
    "\n",
    "    for k, v in pattern_dict.items():\n",
    "        tmp = re.findall(k, smiles)  \n",
    "        if len(tmp) != 0:  \n",
    "            correct = True\n",
    "            sub1 = tmp[0][0]\n",
    "            sub2 = tmp[0][1]           \n",
    "            \n",
    "            backbone = re.sub(r'\\(\\.\\*\\?\\)', 'PLACEHOLDER', k)\n",
    "            backbone = backbone.replace(r'\\(', '(').replace(r'\\)', ')')\n",
    "            \n",
    "            id1 = tokenizer.encode(sub1)  \n",
    "            id2 = tokenizer.encode(sub2)  \n",
    "            if mode == 'double':\n",
    "                masked_smiles = backbone.replace('(PLACEHOLDER)', f\"({'*' * (len(id2)-2)})\")\n",
    "                masked_smiles_cache = masked_smiles.replace(r'PLACEHOLDER\\Z', f\"{'*' * (len(id2)-2)}\")\n",
    "                masked_smiles = masked_smiles_cache.replace('PLACEHOLDER', '*' * (len(id1)-2))\n",
    "                masked_smiles_list.append(masked_smiles)\n",
    "                        \n",
    "            elif mode == 'single':\n",
    "\n",
    "                masked_smiles1 = backbone.replace('(PLACEHOLDER)', f\"({'*' * (len(id2)-2)})\")\n",
    "                masked_smiles1 = masked_smiles1.replace(r'PLACEHOLDER\\Z', f\"{'*' * (len(id2)-2)}\")                \n",
    "                masked_smiles1 = masked_smiles1.replace('PLACEHOLDER', sub1)\n",
    "                masked_smiles_list.append(masked_smiles1)\n",
    "                \n",
    "                masked_smiles2 = backbone.replace('(PLACEHOLDER)', f'({sub2})')\n",
    "                masked_smiles2 = masked_smiles2.replace(r'PLACEHOLDER\\Z', sub2)                \n",
    "                masked_smiles2 = masked_smiles2.replace('PLACEHOLDER', '*' * (len(id1)-2))\n",
    "                masked_smiles_list.append(masked_smiles2)\n",
    "            break  \n",
    "\n",
    "    if not correct:  \n",
    "        raise ValueError(\"Re pattern Error\")  \n",
    "    return masked_smiles_list\n",
    "\n",
    "\n",
    "target_smiles_list = []\n",
    "target_spectra_list = []\n",
    "candidate_smiles_list = []\n",
    "batch_id = []\n",
    "\n",
    "for i in trange(len(test_df)):\n",
    "\n",
    "    target_smiles = test_df['kekule_smiles'].iloc[i]\n",
    "    target_spectra = test_df['raman'].iloc[i]\n",
    "    try:\n",
    "        candidate_smiles = generate_masked_list(target_smiles, mode='single')\n",
    "    except Exception:\n",
    "        continue\n",
    "    else:\n",
    "        target_smiles_list.append(target_smiles)\n",
    "        target_spectra_list.append([target_spectra] * len(candidate_smiles))\n",
    "        candidate_smiles_list.append(candidate_smiles)\n",
    "        batch_id.extend([i] * len(candidate_smiles))\n",
    "# candidate_smiles_smiles_list = [[subitem.replace('*', '<mask>') for subitem in item] for item in candidate_smiles_smiles_list ]\n",
    "\n",
    "(len(target_smiles_list), len(target_spectra_list), len(candidate_smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_smiles_list = [subitem.replace('*', '<mask>') for item in candidate_smiles_list for subitem in item]\n",
    "target_spectra_list = [subitem for item in target_spectra_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:05<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "\n",
    "all_pred_smiles = []\n",
    "all_pred_scores = []\n",
    "correct, total = 0, 0\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, smiles, spectra):\n",
    "        self.smiles = smiles\n",
    "        self.spectra = spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.smiles[idx], self.spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        smiles, spectra = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "test_dataset = TestDataset(masked_smiles_list, target_spectra_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_tokens_logits = model.infer_mlm(batch)\n",
    "    pred_tokens_logits = torch.nn.functional.softmax(pred_tokens_logits, dim=-1)\n",
    "    pred_score, pred_tokens = torch.max(pred_tokens_logits, dim=-1) \n",
    "    \n",
    "    mask = (batch['smiles']['input_ids'] == 4).cpu()\n",
    "    pred_score = [torch.mean(pred_score[i][mask[i]]).item() for i in range(len(pred_score))]\n",
    "    \n",
    "    output = deepcopy(batch['smiles']['input_ids'])\n",
    "    output[mask] = pred_tokens[mask]\n",
    "    \n",
    "    preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    all_pred_smiles.extend(preds)\n",
    "    all_pred_scores.extend(pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1720/1720 [00:00<00:00, 8271.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684 1684 1684 1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out invalid smiles\n",
    "from tqdm import trange\n",
    "\n",
    "valid_pred_smiles = []\n",
    "valid_batch_id = []\n",
    "valid_spectra_list = []\n",
    "valid_scores = []\n",
    "\n",
    "for i in trange(len(all_pred_smiles)):\n",
    "    mol = Chem.MolFromSmiles(all_pred_smiles[i])\n",
    "    if mol is not None:\n",
    "        valid_pred_smiles.append(all_pred_smiles[i])\n",
    "        valid_batch_id.append(batch_id[i])\n",
    "        valid_spectra_list.append(target_spectra_list[i])\n",
    "        valid_scores.append(all_pred_scores[i])\n",
    "        \n",
    "print(len(valid_pred_smiles), len(valid_batch_id), len(valid_spectra_list), len(valid_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 rank by mlm score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.98952\n",
      "top-3:\t\t0.99767\n",
      "top-5:\t\t0.99767\n",
      "top-10:\t\t0.99767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.994898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.987069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top_1     top_3     top_5    top_10\n",
       "ring_count                                        \n",
       "1           0.995745  1.000000  1.000000  1.000000\n",
       "2           0.987245  0.994898  0.994898  0.994898\n",
       "3           0.987069  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    try:\n",
    "        tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    except Exception:\n",
    "        print(tgt_smiles)\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "res = {}\n",
    "valid_scores = np.array(valid_scores)\n",
    "batch_id = np.array(valid_batch_id)\n",
    "\n",
    "for i, bid in enumerate(set(batch_id)):\n",
    "    tmp_pred_score = valid_scores[batch_id == bid]\n",
    "    \n",
    "    tmp_smiles_list = np.array(valid_pred_smiles)[batch_id == bid]\n",
    "    tmp_smiles_list = tmp_smiles_list[np.argsort(-tmp_pred_score)].tolist()\n",
    "    \n",
    "    tmp_pred_score = tmp_pred_score[np.argsort(-tmp_pred_score)].tolist()\n",
    "    tmp_smiles_list = list(dict.fromkeys(tmp_smiles_list))\n",
    "    \n",
    "    res[i] = {\n",
    "              'mlm_score':tmp_pred_score,\n",
    "              'smiles':tmp_smiles_list,\n",
    "              'target_smiles':target_smiles_list[bid], \n",
    "              }\n",
    "\n",
    "df_mlm = pd.DataFrame(res).T\n",
    "df_mlm['ring_count'] = df_mlm['target_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetRingInfo().NumRings())\n",
    "df_mlm['top_1'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:1], row['target_smiles']), axis=1)\n",
    "df_mlm['top_3'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:3], row['target_smiles']), axis=1)\n",
    "df_mlm['top_5'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:5], row['target_smiles']), axis=1)\n",
    "df_mlm['top_10'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:10], row['target_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df_mlm.top_1.mean():.5f}\\ntop-3:\\t\\t{df_mlm.top_3.mean():.5f}\\ntop-5:\\t\\t{df_mlm.top_5.mean():.5f}\\ntop-10:\\t\\t{df_mlm.top_10.mean():.5f}')\n",
    "df_mlm.groupby('ring_count').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 rank by contrastive(retrieval) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  9.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "\n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(valid_spectra_list, valid_pred_smiles)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.92744\n",
      "top-3:\t\t0.92744\n",
      "top-5:\t\t0.92744\n",
      "top-10:\t\t0.92744\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    try:\n",
    "        tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    except Exception:\n",
    "        print(tgt_smiles)\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "res = {}\n",
    "valid_sim_list = np.array(valid_sim_list)\n",
    "valid_scores = np.array(valid_scores)\n",
    "batch_id = np.array(valid_batch_id)\n",
    "\n",
    "for i, bid in enumerate(set(batch_id)):\n",
    "    tmp_pred_score = valid_scores[batch_id == bid]\n",
    "    tmp_sim_list = valid_sim_list[batch_id == bid]\n",
    "    \n",
    "    tmp_smiles_list = np.array(valid_pred_smiles)[batch_id == bid]\n",
    "    tmp_smiles_list = tmp_smiles_list[np.argsort(-tmp_sim_list)].tolist()\n",
    "    \n",
    "    tmp_pred_score = tmp_pred_score[np.argsort(-tmp_sim_list)].tolist()\n",
    "    tmp_sim_list = tmp_sim_list[np.argsort(-tmp_sim_list)].tolist()\n",
    "    \n",
    "\n",
    "    tmp_sim_list = list(dict.fromkeys(tmp_sim_list))\n",
    "    tmp_smiles_list = list(dict.fromkeys(tmp_smiles_list))\n",
    "    \n",
    "    res[i] = {'sim':tmp_sim_list, \n",
    "              'mlm_score':tmp_pred_score,\n",
    "              'smiles':tmp_smiles_list,\n",
    "              'target_smiles':target_smiles_list[bid], # target_smiles_list[i],\n",
    "              }\n",
    "\n",
    "df_mlm = pd.DataFrame(res).T\n",
    "df_mlm['ring_count'] = df_mlm['target_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetRingInfo().NumRings())\n",
    "df_mlm['top_1'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:1], row['target_smiles']), axis=1)\n",
    "df_mlm['top_3'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:3], row['target_smiles']), axis=1)\n",
    "df_mlm['top_5'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:5], row['target_smiles']), axis=1)\n",
    "df_mlm['top_10'] = df_mlm.apply(lambda row: check_beam_mols(row['smiles'][:10], row['target_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df_mlm.top_1.mean():.5f}\\ntop-3:\\t\\t{df_mlm.top_3.mean():.5f}\\ntop-5:\\t\\t{df_mlm.top_5.mean():.5f}\\ntop-10:\\t\\t{df_mlm.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.953052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923754</td>\n",
       "      <td>0.923754</td>\n",
       "      <td>0.923754</td>\n",
       "      <td>0.923754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.906863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top_1     top_3     top_5    top_10\n",
       "ring_count                                        \n",
       "1           0.953052  0.953052  0.953052  0.953052\n",
       "2           0.923754  0.923754  0.923754  0.923754\n",
       "3           0.906863  0.906863  0.906863  0.906863"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlm.groupby('ring_count').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 de novo generation PAHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_PAHs, PretrainModel_Phase\n",
    "from utils.base import seed_everything\n",
    "\n",
    "seed_everything(624)\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt = torch.load('../checkpoints/pahs/raman-kekule_smiles/vib2mol_phase.pth', \n",
    "                  map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(test_df.raman.tolist())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=64)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_smiles.extend(pred_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "res_smiles = []\n",
    "for item in all_pred_smiles:\n",
    "    tmp_mol = Chem.MolFromSmiles(item)\n",
    "    if tmp_mol is not None:\n",
    "        tmp_smiles = Chem.MolToSmiles(tmp_mol, isomericSmiles=False, kekuleSmiles=True, canonical=True)\n",
    "    else:\n",
    "        tmp_smiles = '*'\n",
    "    res_smiles.append(tmp_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.840517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             correct\n",
       "ring_count          \n",
       "1           0.940426\n",
       "2           0.829517\n",
       "3           0.840517"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "\n",
    "def check_mols(pred_smiles, tgt_smiles):\n",
    "    pred_mol = Chem.MolFromSmiles(pred_smiles)\n",
    "    tgt_mol = Chem.MolFromSmiles(tgt_smiles)\n",
    "    if pred_mol is not None and tgt_mol is not None:\n",
    "        if Chem.MolToInchiKey(pred_mol) == Chem.MolToInchiKey(tgt_mol):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "import pandas as pd\n",
    "df_lm = pd.DataFrame({'tgt_smiles':test_df.kekule_smiles.tolist(), 'pred_smiles':res_smiles, 'correct':[check_mols(res_smiles[i], test_df.kekule_smiles.tolist()[i]) for i in range(len(res_smiles))]})\n",
    "df_lm['ring_count'] = df_lm['tgt_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetRingInfo().NumRings())\n",
    "df_lm.groupby('ring_count').mean('correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:55<00:00,  7.90s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "beam_size = 10\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(test_df.raman.tolist())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids_list = model.beam_infer_lm(batch, max_len=64, beam_size=beam_size, temperature=3.5)['pred_ids']\n",
    "    for pred_smiles_ids in pred_smiles_ids_list:\n",
    "        pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "        pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "        all_pred_smiles.append(pred_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 rank by beam score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.86628\n",
      "top-3:\t\t0.91512\n",
      "top-5:\t\t0.91628\n",
      "top-10:\t\t0.91628\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.898219</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.900763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top_1     top_3     top_5    top_10\n",
       "ring_count                                        \n",
       "1           0.953191  0.957447  0.957447  0.957447\n",
       "2           0.824427  0.898219  0.900763  0.900763\n",
       "3           0.849138  0.900862  0.900862  0.900862"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.DataFrame({'tgt_smiles':test_df.kekule_smiles.tolist(), 'pred_smiles':[list(dict.fromkeys(item)) for item in all_pred_smiles]})\n",
    "df['ring_count'] = df['tgt_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetRingInfo().NumRings())\n",
    "df['top_1'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:1], row['tgt_smiles']), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:3], row['tgt_smiles']), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:5], row['tgt_smiles']), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:10], row['tgt_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')\n",
    "df.groupby('ring_count').mean('top_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 rerank by contrastive(retrieval) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_smiles_list = [list(dict.fromkeys(item)) for item in all_pred_smiles]\n",
    "candidate_spectra_list = [[test_df.raman.tolist()[i]] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "tgt_smiles_list = [[test_df.kekule_smiles.tolist()[i]] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "\n",
    "candidate_smiles_list = [subitem for item in candidate_smiles_list for subitem in item]\n",
    "candidate_spectra_list = [subitem for item in candidate_spectra_list for subitem in item]\n",
    "tgt_smiles_list = [subitem for item in tgt_smiles_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(candidate_spectra_list, candidate_smiles_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'target_smiles':tgt_smiles_list, 'pred_smiles':candidate_smiles_list, 'similarity':valid_sim_list})\n",
    "df_sorted = df.sort_values(by=['target_smiles', 'similarity'], ascending=[True, False])\n",
    "\n",
    "grouped = df_sorted.groupby('target_smiles').agg({\n",
    "    'pred_smiles': lambda x: ','.join(x),\n",
    "    'similarity': lambda x: ','.join(map(str, x))\n",
    "}).reset_index()\n",
    "\n",
    "for top_k in [1, 3, 5, 10]: \n",
    "    grouped[f'top_{top_k}'] = grouped.apply(lambda row: check_beam_mols(row['pred_smiles'].split(',')[:top_k], row['target_smiles']) , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall@1:\t0.88140 \n",
      "recall@3:\t0.91512 \n",
      "recall@5:\t0.91628 \n",
      "recall@10:\t0.91628\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.867684</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.900763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.831897</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top_1     top_3     top_5    top_10\n",
       "ring_count                                        \n",
       "1           0.953191  0.957447  0.957447  0.957447\n",
       "2           0.867684  0.900763  0.900763  0.900763\n",
       "3           0.831897  0.896552  0.900862  0.900862"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "recall@1:\\t{grouped.top_1.mean():.5f} \n",
    "recall@3:\\t{grouped.top_3.mean():.5f} \n",
    "recall@5:\\t{grouped.top_5.mean():.5f} \n",
    "recall@10:\\t{grouped.top_10.mean():.5f}\n",
    "    \"\"\")\n",
    "\n",
    "grouped['ring_count'] = grouped['target_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetRingInfo().NumRings())\n",
    "grouped.groupby('ring_count').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
