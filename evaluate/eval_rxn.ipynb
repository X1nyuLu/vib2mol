{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import RXNModel\n",
    "from utils.base import seed_everything\n",
    "\n",
    "seed_everything(624)\n",
    "device = 'cpu'\n",
    "\n",
    "model = build_model('vib2mol_rxn').to(device)\n",
    "\n",
    "# yields\n",
    "# ckpt = torch.load('../checkpoints/rxn/raman-kekule_smiles/vib2mol_phase/yield_fixed.pth', \n",
    "# 0.1\n",
    "# ckpt = torch.load('../checkpoints/rxn/raman-kekule_smiles/vib2mol_phase/yield_10_100.pth',                 \n",
    "# 1.0\n",
    "ckpt = torch.load('../checkpoints/rxn/raman-kekule_smiles/vib2mol_phase/unmixed.pth',                \n",
    "                  map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "db = lmdb.open('../datasets/vibbench/rxn/rxn_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in test_data])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/MolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mix_spectrum(row):\n",
    "    spec_r1 = np.array(row['reactant1_raman'])\n",
    "    spec_r2 = np.array(row['reactant2_raman'])\n",
    "    spec_p = np.array(row['product_raman'])\n",
    "    weight = row['Yield']\n",
    "    return (0.5-0.5*weight) * (spec_r1 + spec_r2) + weight * spec_p\n",
    "\n",
    "test_df['mix_raman'] = test_df.apply(lambda row: mix_spectrum(row), axis=1)\n",
    "test_df = test_df[test_df.Yield <= 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 evaluating retrieval performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, spectra, smiles):\n",
    "        self.spectra = spectra\n",
    "        self.smiles = smiles\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.spectra[idx], self.smiles[idx]\n",
    "    \n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer, spectral_types=None, smiles_types=None, mix_ratio=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.spectral_types = spectral_types\n",
    "        self.smiles_types = smiles_types\n",
    "        self.mix_ratio = mix_ratio\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        spectra, smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        \n",
    "        input_ids = self.tokenizer(list(smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        \n",
    "        batch_data = {'raman':spectra, 'smiles':input_ids}\n",
    "\n",
    "        return {'batch_size':len(spectra), 'target':None, 'data': batch_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:25<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = TestDataset(test_df['product_raman'].to_list(), test_df['product_kekule_smiles'].to_list())\n",
    "# test_dataset = TestDataset(test_df['mix_raman'].to_list(), test_df['product_kekule_smiles'].to_list())\n",
    "\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "all_smiles_embeddings = []\n",
    "all_spectra_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_bar:\n",
    "        data = batch['data']\n",
    "        batch_size = batch['batch_size']\n",
    "        output = model(data, return_proj_output=True, return_loss=False)\n",
    "                    \n",
    "        all_smiles_embeddings.append(output['molecular_proj_output'].detach().cpu())\n",
    "        all_spectra_embeddings.append(output['spectral_proj_output'].detach().cpu())\n",
    "\n",
    "    all_smiles_embeddings = torch.cat(all_smiles_embeddings, dim=0)\n",
    "    all_spectra_embeddings = torch.cat(all_spectra_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@1:0.84874\n",
      "recall@3:0.97378\n",
      "recall@5:0.98849\n",
      "recall@10:0.99712\n",
      "recall@100:1.00000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_recall(similarity_matrix, k, verbose=False):\n",
    "    num_queries = similarity_matrix.size(0)\n",
    "    _, topk_indices = similarity_matrix.topk(k, dim=1, largest=True, sorted=True)\n",
    "    \n",
    "    correct_list = []\n",
    "    for i in range(num_queries):\n",
    "        if i in topk_indices[i]:\n",
    "            correct_list.append(1)\n",
    "        else:\n",
    "            correct_list.append(0)\n",
    "    recall_at_k = sum(correct_list) / num_queries\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'recall@{k}:{recall_at_k:.5f}')\n",
    "    else:\n",
    "        return recall_at_k, correct_list\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(all_spectra_embeddings, all_smiles_embeddings)\n",
    "compute_recall(similarity_matrix, k=1, verbose=True)\n",
    "compute_recall(similarity_matrix, k=3, verbose=True)\n",
    "compute_recall(similarity_matrix, k=5, verbose=True)\n",
    "compute_recall(similarity_matrix, k=10, verbose=True)\n",
    "compute_recall(similarity_matrix, k=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 de novo generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len:56\n"
     ]
    }
   ],
   "source": [
    "length = [len(item) for item in test_df['product_kekule_smiles']]\n",
    "max_len = max(length)+2\n",
    "print(f'max_len:{max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:23<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(test_df['product_raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=max_len)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_smiles.extend(pred_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "\n",
    "def check_mols(pred_smiles, tgt_smiles):\n",
    "    pred_mol = Chem.MolFromSmiles(pred_smiles)\n",
    "    tgt_mol = Chem.MolFromSmiles(tgt_smiles)\n",
    "    if pred_mol is not None and tgt_mol is not None:\n",
    "        if Chem.MolToInchiKey(pred_mol) == Chem.MolToInchiKey(tgt_mol):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "res_smiles = []\n",
    "for item in all_pred_smiles:\n",
    "    tmp_mol = Chem.MolFromSmiles(item)\n",
    "    if tmp_mol is not None:\n",
    "        tmp_smiles = Chem.MolToSmiles(tmp_mol, isomericSmiles=False, kekuleSmiles=True, canonical=True)\n",
    "    else:\n",
    "        tmp_smiles = '*'\n",
    "    res_smiles.append(tmp_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3127/3127 [00:03<00:00, 957.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.277582347297727 %\n",
      "0.16277582347297728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'pred':res_smiles, 'tgt':test_df['product_kekule_smiles'].to_list(), 'correct':[check_mols(res_smiles[i], test_df['product_kekule_smiles'].to_list()[i]) for i in trange(len(test_df))]})\n",
    "print(f'{df.correct.mean() * 100} %')\n",
    "print(df.correct.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% train and 100% test -> 0.23529411764705882\n",
    "# 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100 %\n",
    "greedy = [0.16277582347297728,\n",
    "          0.17742966751918157,\n",
    "          0.17647058823529413,\n",
    "          0.17998721227621484, \n",
    "          0.19629156010230178, \n",
    "          0.24168797953964194, \n",
    "          0.24008951406649617, \n",
    "          0.23497442455242967, \n",
    "          0.22730179028132994, \n",
    "          0.1969309462915601, \n",
    "          0.07768542199488492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [09:11<00:00, 22.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "beam_size = 10\n",
    "\n",
    "all_pred_smiles = []\n",
    "# test_dataset = TestDataset(test_df['mix_raman'].to_list())\n",
    "test_dataset = TestDataset(test_df['product_raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids_list = model.beam_infer_lm(batch, max_len=64, beam_size=beam_size, temperature=3.5)['pred_ids']\n",
    "    for pred_smiles_ids in pred_smiles_ids_list:\n",
    "        pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "        pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "        all_pred_smiles.append(pred_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 rank by beam score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.25584\n",
      "top-3:\t\t0.34954\n",
      "top-5:\t\t0.36137\n",
      "top-10:\t\t0.36329\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'tgt_smiles':test_df['product_kekule_smiles'].to_list(), \n",
    "                   'pred_smiles':[list(dict.fromkeys(item)) for item in all_pred_smiles],\n",
    "                   'rxntype':test_df['rxntype'].to_list(),\n",
    "                   'yield':test_df['Yield'].to_list()})\n",
    "\n",
    "df['top_1'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:1], row['tgt_smiles']), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:3], row['tgt_smiles']), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:5], row['tgt_smiles']), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:10], row['tgt_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 rerank by retrieval module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_smiles_list = [list(set(item)) for item in all_pred_smiles]\n",
    "candidate_spectra_list = [[test_df['mix_raman'].to_list()[i]] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "tgt_smiles_list = [[test_df['product_kekule_smiles'].to_list()[i]] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "\n",
    "candidate_smiles_list = [subitem for item in candidate_smiles_list for subitem in item]\n",
    "candidate_spectra_list = [subitem for item in candidate_spectra_list for subitem in item]\n",
    "tgt_smiles_list = [subitem for item in tgt_smiles_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:11<00:00, 16.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(candidate_spectra_list, candidate_smiles_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'target_smiles':tgt_smiles_list, 'pred_smiles':candidate_smiles_list, 'similarity':valid_sim_list})\n",
    "# sort by 'target_smiles' and 'similarity' in descending order\n",
    "df_sorted = df.sort_values(by=['target_smiles', 'similarity'], ascending=[True, False])\n",
    "\n",
    "# group by 'target_smiles' and aggregate 'pred_smiles' and 'similarity'\n",
    "grouped = df_sorted.groupby('target_smiles').agg({\n",
    "    'pred_smiles': lambda x: ','.join(x),\n",
    "    'similarity': lambda x: ','.join(map(str, x))\n",
    "}).reset_index()\n",
    "\n",
    "# calculate recall@k\n",
    "for top_k in [1, 3, 5, 10]: \n",
    "    grouped[f'top_{top_k}_recall'] = grouped.apply(lambda row: row['target_smiles'] in row['pred_smiles'].split(',')[:top_k], axis=1)\n",
    "\n",
    "grouped['rank'] = grouped.apply(lambda row: (row['pred_smiles'].split(',').index(row['target_smiles']))+1 if row['target_smiles'] in row['pred_smiles'].split(',') else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall@1:\t0.23148 \n",
      "recall@3:\t0.31420 \n",
      "recall@5:\t0.32126 \n",
      "recall@10:\t0.32190\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "recall@1:\\t{grouped.top_1_recall.mean():.5f} \n",
    "recall@3:\\t{grouped.top_3_recall.mean():.5f} \n",
    "recall@5:\\t{grouped.top_5_recall.mean():.5f} \n",
    "recall@10:\\t{grouped.top_10_recall.mean():.5f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
