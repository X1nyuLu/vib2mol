{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5191 [00:00<?, ?it/s]/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38442/2817359459.py:12: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  test_df = pd.DataFrame([pickle.loads(item[1]) for item in tqdm(test_data)])\n",
      "100%|██████████| 5191/5191 [00:00<00:00, 99729.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lmdb\n",
    "import pickle\n",
    "from tqdm.auto import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "db = lmdb.open('../datasets/vibench/peptide/peptide_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in tqdm(test_data)])\n",
    "device = 'cpu'\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'sequence': input_ids,  'spectra':spectra}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "\n",
    "torch.manual_seed(624)\n",
    "device = 'cpu'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt_path = '../checkpoints/peptide/raman-kekule_smiles/vib2mol_phase.pth'\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = f'../models/MolTokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "test_dataset = TestDataset(test_df.raman.to_list(), test_df.kekule_smiles.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "\n",
    "torch.manual_seed(624)\n",
    "device = 'cpu'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt_path = '../checkpoints/peptide/raman-sequence/vib2mol_phase.pth'\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = '../models/PepTokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "test_dataset = TestDataset(test_df.raman.to_list(), test_df.sequence.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate similarity between molecules and spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [02:23<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "all_molecular_embeddings = []\n",
    "all_spectral_embeddings = []\n",
    "\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        \n",
    "        all_molecular_embeddings.append(molecular_embedding)\n",
    "        all_spectral_embeddings.append(spectral_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@1:0.67579\n",
      "recall@3:0.89886\n",
      "recall@5:0.94722\n",
      "recall@10:0.97765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_recall(similarity_matrix, k, return_result=False):\n",
    "    num_queries = similarity_matrix.size(0)\n",
    "    _, topk_indices = similarity_matrix.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct_list = []\n",
    "    for i in range(num_queries):\n",
    "        if i in topk_indices[i]:\n",
    "            correct_list.append(1)\n",
    "        else:\n",
    "            correct_list.append(0)\n",
    "    recall_at_k = sum(correct_list) / num_queries\n",
    "    \n",
    "    print(f'recall@{k}:{recall_at_k:.5f}')\n",
    "    if return_result:\n",
    "        return correct_list\n",
    "\n",
    "all_molecular_embeddings = torch.cat(all_molecular_embeddings)\n",
    "all_spectral_embeddings = torch.cat(all_spectral_embeddings)\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(all_spectral_embeddings, all_molecular_embeddings)\n",
    "top1 = compute_recall(similarity_matrix, k=1, return_result=True)\n",
    "top3 = compute_recall(similarity_matrix, k=3, return_result=True)\n",
    "compute_recall(similarity_matrix, k=5, return_result=False)\n",
    "compute_recall(similarity_matrix, k=10, return_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38442/2079386055.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['top_1'] = top1\n",
      "/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38442/2079386055.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['top_3'] = top3\n",
      "/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38442/2079386055.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length'] = df.apply(lambda row: len(row['sequence'].split('-')), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.775586</td>\n",
       "      <td>0.944513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.654767</td>\n",
       "      <td>0.889452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           top_1     top_3\n",
       "length                    \n",
       "2       0.947368  1.000000\n",
       "3       0.775586  0.944513\n",
       "4       0.654767  0.889452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_df[:]\n",
    "df['top_1'] = top1\n",
    "df['top_3'] = top3\n",
    "df['length'] = df.apply(lambda row: len(row['sequence'].split('-')), axis=1)\n",
    "df.groupby('length').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 de novo generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5191 [00:00<?, ?it/s]/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38442/2397482961.py:12: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  test_df = pd.DataFrame([pickle.loads(item[1]) for item in tqdm(test_data)])\n",
      "100%|██████████| 5191/5191 [00:00<00:00, 135771.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "db = lmdb.open('../datasets/vibench/peptide/peptide_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in tqdm(test_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>norm_smiles</th>\n",
       "      <th>kekule_smiles</th>\n",
       "      <th>raman</th>\n",
       "      <th>ir</th>\n",
       "      <th>filename</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...</td>\n",
       "      <td>CCC(C)C(NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(Cc1ccccc1...</td>\n",
       "      <td>CCC(C)C(NC(=O)C(CC1=CC=C(O)C=C1)NC(=O)C(CC1=CC...</td>\n",
       "      <td>[0.031817872173130125, 0.04253405263639632, 0....</td>\n",
       "      <td>[0.008984905034481022, 0.012997145252672785, 0...</td>\n",
       "      <td>G-F-Y-I</td>\n",
       "      <td>G-F-Y-I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@@H](C...</td>\n",
       "      <td>CC(NC(=O)C(N)Cc1ccccc1)C(=O)NC(Cc1ccccc1)C(=O)...</td>\n",
       "      <td>CC(NC(=O)C(N)CC1=CC=CC=C1)C(=O)NC(CC1=CC=CC=C1...</td>\n",
       "      <td>[0.03639097157542858, 0.03839822624049318, 0.0...</td>\n",
       "      <td>[0.019057326865201937, 0.02214613556867351, 0....</td>\n",
       "      <td>F-A-F-H</td>\n",
       "      <td>F-A-F-H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSCC[C@H](NC(=O)[C@H](C)NC(=O)[C@@H](N)Cc1c[nH...</td>\n",
       "      <td>CSCCC(NC(=O)C(C)NC(=O)C(N)Cc1c[nH]cn1)C(=O)NC(...</td>\n",
       "      <td>CSCCC(NC(=O)C(C)NC(=O)C(N)CC1=CNC=N1)C(=O)NC(C...</td>\n",
       "      <td>[0.010788252706046516, 0.012695604522622993, 0...</td>\n",
       "      <td>[0.01820227941387322, 0.019182739075950875, 0....</td>\n",
       "      <td>H-A-M-V</td>\n",
       "      <td>H-A-M-V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@@H](NC(=O)...</td>\n",
       "      <td>CC(C)CC(NC(=O)C(CO)NC(=O)C(NC(=O)C(N)Cc1ccccc1...</td>\n",
       "      <td>CC(C)CC(NC(=O)C(CO)NC(=O)C(NC(=O)C(N)CC1=CC=CC...</td>\n",
       "      <td>[0.010883635762013337, 0.011228595019176968, 0...</td>\n",
       "      <td>[0.010824394450446622, 0.012379132733776744, 0...</td>\n",
       "      <td>F-V-S-L</td>\n",
       "      <td>F-V-S-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N[C@@H](Cc1ccccc1)C(=O)N[C@@H](CS)C(=O)N[C@@H]...</td>\n",
       "      <td>NC(Cc1ccccc1)C(=O)NC(CS)C(=O)NC(CC(=O)O)C(=O)O</td>\n",
       "      <td>NC(CC1=CC=CC=C1)C(=O)NC(CS)C(=O)NC(CC(=O)O)C(=O)O</td>\n",
       "      <td>[0.031162503659202024, 0.046240888283535654, 0...</td>\n",
       "      <td>[0.025249009656411414, 0.037494951225140724, 0...</td>\n",
       "      <td>F-C-D</td>\n",
       "      <td>F-C-D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  \\\n",
       "0  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...   \n",
       "1  C[C@H](NC(=O)[C@@H](N)Cc1ccccc1)C(=O)N[C@@H](C...   \n",
       "2  CSCC[C@H](NC(=O)[C@H](C)NC(=O)[C@@H](N)Cc1c[nH...   \n",
       "3  CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@@H](NC(=O)...   \n",
       "4  N[C@@H](Cc1ccccc1)C(=O)N[C@@H](CS)C(=O)N[C@@H]...   \n",
       "\n",
       "                                         norm_smiles  \\\n",
       "0  CCC(C)C(NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(Cc1ccccc1...   \n",
       "1  CC(NC(=O)C(N)Cc1ccccc1)C(=O)NC(Cc1ccccc1)C(=O)...   \n",
       "2  CSCCC(NC(=O)C(C)NC(=O)C(N)Cc1c[nH]cn1)C(=O)NC(...   \n",
       "3  CC(C)CC(NC(=O)C(CO)NC(=O)C(NC(=O)C(N)Cc1ccccc1...   \n",
       "4     NC(Cc1ccccc1)C(=O)NC(CS)C(=O)NC(CC(=O)O)C(=O)O   \n",
       "\n",
       "                                       kekule_smiles  \\\n",
       "0  CCC(C)C(NC(=O)C(CC1=CC=C(O)C=C1)NC(=O)C(CC1=CC...   \n",
       "1  CC(NC(=O)C(N)CC1=CC=CC=C1)C(=O)NC(CC1=CC=CC=C1...   \n",
       "2  CSCCC(NC(=O)C(C)NC(=O)C(N)CC1=CNC=N1)C(=O)NC(C...   \n",
       "3  CC(C)CC(NC(=O)C(CO)NC(=O)C(NC(=O)C(N)CC1=CC=CC...   \n",
       "4  NC(CC1=CC=CC=C1)C(=O)NC(CS)C(=O)NC(CC(=O)O)C(=O)O   \n",
       "\n",
       "                                               raman  \\\n",
       "0  [0.031817872173130125, 0.04253405263639632, 0....   \n",
       "1  [0.03639097157542858, 0.03839822624049318, 0.0...   \n",
       "2  [0.010788252706046516, 0.012695604522622993, 0...   \n",
       "3  [0.010883635762013337, 0.011228595019176968, 0...   \n",
       "4  [0.031162503659202024, 0.046240888283535654, 0...   \n",
       "\n",
       "                                                  ir filename sequence  \n",
       "0  [0.008984905034481022, 0.012997145252672785, 0...  G-F-Y-I  G-F-Y-I  \n",
       "1  [0.019057326865201937, 0.02214613556867351, 0....  F-A-F-H  F-A-F-H  \n",
       "2  [0.01820227941387322, 0.019182739075950875, 0....  H-A-M-V  H-A-M-V  \n",
       "3  [0.010824394450446622, 0.012379132733776744, 0...  F-V-S-L  F-V-S-L  \n",
       "4  [0.025249009656411414, 0.037494951225140724, 0...    F-C-D    F-C-D  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "\n",
    "torch.manual_seed(624)\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt_path = '../checkpoints/peptide/raman-kekule_smiles/vib2mol_phase.pth'\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = '../models/MolTokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len:99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:42<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "length = [len(test_df.iloc[i]['kekule_smiles']) for i in range(len(test_df))]\n",
    "max_len = max(length)+2\n",
    "print(f'max_len:{max_len}')\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=max_len)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_smiles.extend(pred_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25794644577152764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_mols(pred_smiles, tgt_smiles):\n",
    "    pred_mol = Chem.MolFromSmiles(pred_smiles)\n",
    "    tgt_mol = Chem.MolFromSmiles(tgt_smiles)\n",
    "    if pred_mol is not None and tgt_mol is not None:\n",
    "        if Chem.MolToInchiKey(pred_mol) == Chem.MolToInchiKey(tgt_mol):\n",
    "            return 1\n",
    "    return 0\n",
    "    \n",
    "df = pd.DataFrame({'tgt_seq':test_df['kekule_smiles'].to_list(), 'pred_seq':all_pred_smiles})\n",
    "df['top_1'] = df.apply(lambda row: check_mols(row['tgt_seq'], row['pred_seq']), axis=1)\n",
    "print(df.top_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 beam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 325/325 [23:12<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids_list = model.beam_infer_lm(batch, max_len=max_len, beam_size=10, temperature=3.5)['pred_ids']\n",
    "    for pred_smiles_ids in pred_smiles_ids_list:\n",
    "        pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "        pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "        all_pred_smiles.append(pred_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.26296\n",
      "top-3:\t\t0.41090\n",
      "top-5:\t\t0.42728\n",
      "top-10:\t\t0.42901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def check_beam_mols(tgt_smiles, pred_smiles_list):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_smiles':test_df['kekule_smiles'].to_list(), 'pred_smiles':[list(dict.fromkeys(item)) for item in all_pred_smiles]})\n",
    "df['top_1'] = df.apply(lambda row: check_beam_mols(row['tgt_smiles'], row['pred_smiles'][:1]), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_mols(row['tgt_smiles'], row['pred_smiles'][:3]), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_mols(row['tgt_smiles'], row['pred_smiles'][:5]), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_mols(row['tgt_smiles'], row['pred_smiles'][:10]), axis=1)\n",
    "\n",
    "# df['token_acc'] = df.apply(lambda row: token_accuracy(row['tgt_smiles'], row['pred_smiles'][0]), axis=1)\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 rerank by retrieval module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_smiles_list = [list(set(item)) for item in all_pred_smiles]\n",
    "candidate_spectra_list = [[test_df.iloc[i]['raman']] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "tgt_smiles_list = [[test_df.iloc[i]['kekule_smiles']] * len(item) for i, item in enumerate(candidate_smiles_list)]\n",
    "\n",
    "candidate_smiles_list = [subitem for item in candidate_smiles_list for subitem in item]\n",
    "candidate_spectra_list = [subitem for item in candidate_spectra_list for subitem in item]\n",
    "tgt_smiles_list = [subitem for item in tgt_smiles_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233/233 [00:34<00:00,  6.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'sequence': input_ids,  'spectra':spectra}\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(candidate_spectra_list, candidate_smiles_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall@1:\t0.27555 \n",
      "recall@3:\t0.40879 \n",
      "recall@5:\t0.41689 \n",
      "recall@10:\t0.41728\n",
      "recall@100:\t0.41728\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'target_smiles':tgt_smiles_list, 'pred_smiles':candidate_smiles_list, 'similarity':valid_sim_list})\n",
    "# 首先按照 'target_smiles' 和 'similarity' 降序排序\n",
    "df_sorted = df.sort_values(by=['target_smiles', 'similarity'], ascending=[True, False])\n",
    "\n",
    "# 然后按照 'target_smiles' 分组，并对 'pred_smiles' 和 'similarity' 进行聚合\n",
    "grouped = df_sorted.groupby('target_smiles').agg({\n",
    "    'pred_smiles': lambda x: ','.join(x),\n",
    "    'similarity': lambda x: ','.join(map(str, x))\n",
    "}).reset_index()\n",
    "\n",
    "# 应用函数计算每个 target_smiles 的 TOP-K recall\n",
    "for top_k in [1, 3, 5, 10, 100]: \n",
    "    grouped[f'top_{top_k}_recall'] = grouped.apply(lambda row: row['target_smiles'].replace('-', '') in row['pred_smiles'].split(',')[:top_k], axis=1)\n",
    "\n",
    "grouped['rank'] = grouped.apply(lambda row: (row['pred_smiles'].split(',').index(row['target_smiles']))+1 if row['target_smiles'] in row['pred_smiles'].split(',') else 0, axis=1)\n",
    "grouped['length'] = grouped.apply(lambda row: len(row['target_smiles']), axis=1)\n",
    "\n",
    "print(f\"\"\"\n",
    "recall@1:\\t{grouped.top_1_recall.mean():.5f} \n",
    "recall@3:\\t{grouped.top_3_recall.mean():.5f} \n",
    "recall@5:\\t{grouped.top_5_recall.mean():.5f} \n",
    "recall@10:\\t{grouped.top_10_recall.mean():.5f}\n",
    "recall@100:\\t{grouped.top_100_recall.mean():.5f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "\n",
    "torch.manual_seed(624)\n",
    "device = 'cpu'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt_path = '../checkpoints/peptide/raman-sequence/vib2mol_phase.pth'\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = '../models/PepTokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 greddy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:31<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_sequences = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=6)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_sequences.extend(pred_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3515700250433442\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_seq(tgt_seq, pred_seq):\n",
    "    tgt_seq = tgt_seq.replace('-', '')\n",
    "    if tgt_seq == pred_seq:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_seq':test_df['sequence'].to_list(), 'pred_seq':all_pred_sequences})\n",
    "df['top_1'] = df.apply(lambda row: check_seq(row['tgt_seq'], row['pred_seq']), axis=1)\n",
    "print(df.top_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 beam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_sequence = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_sequence_ids_list = model.beam_infer_lm(batch, max_len=6, beam_size=10, temperature=17.5)['pred_ids']\n",
    "    for pred_sequence_ids in pred_sequence_ids_list:\n",
    "        pred_sequence = tokenizer.batch_decode(pred_sequence_ids)\n",
    "        pred_sequence = [item.split('</s>')[0].replace('<s>', '') for item in pred_sequence]\n",
    "        all_pred_sequence.append(pred_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.27259\n",
      "top-3:\t\t0.49586\n",
      "top-5:\t\t0.54749\n",
      "top-10:\t\t0.56694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def check_beam_seq(tgt_seq, pred_seq_list):\n",
    "    tgt_seq = tgt_seq.replace('-', '')\n",
    "    pred_mol_list = []\n",
    "    if tgt_seq in pred_seq_list:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_seq':test_df['sequence'].to_list(), 'pred_seq':[list(dict.fromkeys(item)) for item in all_pred_sequence]})\n",
    "df['top_1'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:1]), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:3]), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:5]), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:10]), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tgt_seq</th>\n",
       "      <th>pred_seq</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G-F-Y-I</td>\n",
       "      <td>[GVYI, GYYI, GYFI, GIYI, GYIF, GLYI]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-A-F-H</td>\n",
       "      <td>[FAFH, FAPH, FAMH]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H-A-M-V</td>\n",
       "      <td>[HMA, GHAV, HGAV, HMAV, HCAV, HFAV, GHAM, HMDV]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F-V-S-L</td>\n",
       "      <td>[FTL, FTVL, FALL, FTCF, FTAL, FTFL, FTCL, FTTL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F-C-D</td>\n",
       "      <td>[FDC]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tgt_seq                                           pred_seq  top_1  top_3  \\\n",
       "0  G-F-Y-I               [GVYI, GYYI, GYFI, GIYI, GYIF, GLYI]      0      0   \n",
       "1  F-A-F-H                                 [FAFH, FAPH, FAMH]      1      1   \n",
       "2  H-A-M-V    [HMA, GHAV, HGAV, HMAV, HCAV, HFAV, GHAM, HMDV]      0      0   \n",
       "3  F-V-S-L  [FTL, FTVL, FALL, FTCF, FTAL, FTFL, FTCL, FTTL...      0      0   \n",
       "4    F-C-D                                              [FDC]      0      0   \n",
       "\n",
       "   top_5  top_10  \n",
       "0      0       0  \n",
       "1      1       1  \n",
       "2      0       0  \n",
       "3      0       0  \n",
       "4      0       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 rerank by retrieval module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sequence_list = [list(set(item)) for item in all_pred_sequence]\n",
    "candidate_spectra_list = [[test_df.iloc[i]['raman']] * len(item) for i, item in enumerate(candidate_sequence_list)]\n",
    "tgt_sequence_list = [[test_df.iloc[i]['sequence']] * len(item) for i, item in enumerate(candidate_sequence_list)]\n",
    "\n",
    "candidate_sequence_list = [subitem for item in candidate_sequence_list for subitem in item]\n",
    "candidate_spectra_list = [subitem for item in candidate_spectra_list for subitem in item]\n",
    "tgt_sequence_list = [subitem for item in tgt_sequence_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:50<00:00,  7.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_sequence):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_sequence = pred_sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_sequence[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_sequence = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_sequence), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'sequence': input_ids,  'spectra':spectra}\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(candidate_spectra_list, candidate_sequence_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall@1:\t0.39915 \n",
      "recall@3:\t0.55288 \n",
      "recall@5:\t0.56502 \n",
      "recall@10:\t0.56694\n",
      "recall@100:\t0.56694\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tgt_sequence_list = [item.replace('-', '') for item in tgt_sequence_list]\n",
    "df = pd.DataFrame({'target_sequence':tgt_sequence_list, 'pred_sequence':candidate_sequence_list, 'similarity':valid_sim_list})\n",
    "\n",
    "df_sorted = df.sort_values(by=['target_sequence', 'similarity'], ascending=[True, False])\n",
    "\n",
    "df = df_sorted.groupby('target_sequence').agg({\n",
    "    'pred_sequence': lambda x: ','.join(x),\n",
    "    'similarity': lambda x: ','.join(map(str, x))\n",
    "}).reset_index()\n",
    "\n",
    "for top_k in [1, 3, 5, 10, 100]: \n",
    "    df[f'top_{top_k}_recall'] = df.apply(lambda row: row['target_sequence'].replace('-', '') in row['pred_sequence'].split(',')[:top_k], axis=1)\n",
    "\n",
    "df['rank'] = df.apply(lambda row: (row['pred_sequence'].split(',').index(row['target_sequence']))+1 if row['target_sequence'] in row['pred_sequence'].split(',') else 0, axis=1)\n",
    "df['length'] = df.apply(lambda row: len(row['target_sequence']), axis=1)\n",
    "\n",
    "print(f\"\"\"\n",
    "recall@1:\\t{df.top_1_recall.mean():.5f} \n",
    "recall@3:\\t{df.top_3_recall.mean():.5f} \n",
    "recall@5:\\t{df.top_5_recall.mean():.5f} \n",
    "recall@10:\\t{df.top_10_recall.mean():.5f}\n",
    "recall@100:\\t{df.top_100_recall.mean():.5f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1_recall</th>\n",
       "      <th>top_3_recall</th>\n",
       "      <th>top_5_recall</th>\n",
       "      <th>top_10_recall</th>\n",
       "      <th>top_100_recall</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552404</td>\n",
       "      <td>0.683107</td>\n",
       "      <td>0.692972</td>\n",
       "      <td>0.692972</td>\n",
       "      <td>0.692972</td>\n",
       "      <td>0.885327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366191</td>\n",
       "      <td>0.525104</td>\n",
       "      <td>0.537771</td>\n",
       "      <td>0.540074</td>\n",
       "      <td>0.540074</td>\n",
       "      <td>0.777982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        top_1_recall  top_3_recall  top_5_recall  top_10_recall  \\\n",
       "length                                                            \n",
       "2           0.894737      0.947368      0.947368       0.947368   \n",
       "3           0.552404      0.683107      0.692972       0.692972   \n",
       "4           0.366191      0.525104      0.537771       0.540074   \n",
       "\n",
       "        top_100_recall      rank  \n",
       "length                            \n",
       "2             0.947368  1.000000  \n",
       "3             0.692972  0.885327  \n",
       "4             0.540074  0.777982  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('length').mean('top_1_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 modified site retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 2511/2511 [00:00<00:00, 63137.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "db = lmdb.open('../datasets/vibench/peptide_mod/peptide_mod_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in tqdm(test_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import PretrainModel_Phase\n",
    "\n",
    "torch.manual_seed(624)\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt_path = '../checkpoints/peptide_mod/raman-sequence/vib2mol_phase.pth'\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path = '../models/PepTokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>norm_smiles</th>\n",
       "      <th>kekule_smiles</th>\n",
       "      <th>raman</th>\n",
       "      <th>ir</th>\n",
       "      <th>filename</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C[C@@H](OS(=O)(=O)O)[C@@H](NC(=O)[C@H](CCC(=O)...</td>\n",
       "      <td>CC(OS(=O)(=O)O)C(NC(=O)C(CCC(=O)NC(=O)CCC(N)C(...</td>\n",
       "      <td>CC(OS(=O)(=O)O)C(NC(=O)C(CCC(=O)NC(=O)CCC(N)C(...</td>\n",
       "      <td>[0.0610237247023169, 0.07534843062887989, 0.08...</td>\n",
       "      <td>[0.011994992794439888, 0.01829167933971773, 0....</td>\n",
       "      <td>C-E-sT-Q</td>\n",
       "      <td>C-E-sT-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)[C@H](NC(=O)CNC(=O)[C@@H](N)COS(=O)(=O)O)...</td>\n",
       "      <td>CC(C)C(NC(=O)CNC(=O)C(N)COS(=O)(=O)O)C(=O)O</td>\n",
       "      <td>CC(C)C(NC(=O)CNC(=O)C(N)COS(=O)(=O)O)C(=O)O</td>\n",
       "      <td>[0.057882732891363045, 0.04388163818948183, 0....</td>\n",
       "      <td>[0.019754579708913297, 0.015484649837671371, 0...</td>\n",
       "      <td>sS-G-V</td>\n",
       "      <td>sS-G-V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N[C@@H](Cc1ccc(O)cc1)C(=O)NCC(=O)N[C@@H](Cc1c[...</td>\n",
       "      <td>NC(Cc1ccc(O)cc1)C(=O)NCC(=O)NC(Cc1c[nH]c2ccccc...</td>\n",
       "      <td>NC(CC1=CC=C(O)C=C1)C(=O)NCC(=O)NC(CC1=CNC2=CC=...</td>\n",
       "      <td>[0.025843460103289473, 0.022190718157910284, 0...</td>\n",
       "      <td>[0.06034964879213473, 0.04087290119317211, 0.0...</td>\n",
       "      <td>Y-G-W</td>\n",
       "      <td>Y-G-W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC[C@H](C)[C@H](N)C(=O)N[C@@H](C(=O)N[C@@H](C)...</td>\n",
       "      <td>CCC(C)C(N)C(=O)NC(C(=O)NC(C)C(=O)O)C(C)OP(=O)(O)O</td>\n",
       "      <td>CCC(C)C(N)C(=O)NC(C(=O)NC(C)C(=O)O)C(C)OP(=O)(O)O</td>\n",
       "      <td>[0.0727303876705453, 0.05813604322334051, 0.04...</td>\n",
       "      <td>[0.02712906135457303, 0.01848644633855094, 0.0...</td>\n",
       "      <td>I-pT-A</td>\n",
       "      <td>I-pT-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCC(=O)N[C@@H](COS(=O)(=O)O)C(=O)N[C@@H](CS)C(...</td>\n",
       "      <td>NCC(=O)NC(COS(=O)(=O)O)C(=O)NC(CS)C(=O)O</td>\n",
       "      <td>NCC(=O)NC(COS(=O)(=O)O)C(=O)NC(CS)C(=O)O</td>\n",
       "      <td>[0.06237074766339497, 0.0889687593086402, 0.14...</td>\n",
       "      <td>[0.010306055339872014, 0.016394710928848952, 0...</td>\n",
       "      <td>G-sS-C</td>\n",
       "      <td>G-sS-C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  \\\n",
       "0  C[C@@H](OS(=O)(=O)O)[C@@H](NC(=O)[C@H](CCC(=O)...   \n",
       "1  CC(C)[C@H](NC(=O)CNC(=O)[C@@H](N)COS(=O)(=O)O)...   \n",
       "2  N[C@@H](Cc1ccc(O)cc1)C(=O)NCC(=O)N[C@@H](Cc1c[...   \n",
       "3  CC[C@H](C)[C@H](N)C(=O)N[C@@H](C(=O)N[C@@H](C)...   \n",
       "4  NCC(=O)N[C@@H](COS(=O)(=O)O)C(=O)N[C@@H](CS)C(...   \n",
       "\n",
       "                                         norm_smiles  \\\n",
       "0  CC(OS(=O)(=O)O)C(NC(=O)C(CCC(=O)NC(=O)CCC(N)C(...   \n",
       "1        CC(C)C(NC(=O)CNC(=O)C(N)COS(=O)(=O)O)C(=O)O   \n",
       "2  NC(Cc1ccc(O)cc1)C(=O)NCC(=O)NC(Cc1c[nH]c2ccccc...   \n",
       "3  CCC(C)C(N)C(=O)NC(C(=O)NC(C)C(=O)O)C(C)OP(=O)(O)O   \n",
       "4           NCC(=O)NC(COS(=O)(=O)O)C(=O)NC(CS)C(=O)O   \n",
       "\n",
       "                                       kekule_smiles  \\\n",
       "0  CC(OS(=O)(=O)O)C(NC(=O)C(CCC(=O)NC(=O)CCC(N)C(...   \n",
       "1        CC(C)C(NC(=O)CNC(=O)C(N)COS(=O)(=O)O)C(=O)O   \n",
       "2  NC(CC1=CC=C(O)C=C1)C(=O)NCC(=O)NC(CC1=CNC2=CC=...   \n",
       "3  CCC(C)C(N)C(=O)NC(C(=O)NC(C)C(=O)O)C(C)OP(=O)(O)O   \n",
       "4           NCC(=O)NC(COS(=O)(=O)O)C(=O)NC(CS)C(=O)O   \n",
       "\n",
       "                                               raman  \\\n",
       "0  [0.0610237247023169, 0.07534843062887989, 0.08...   \n",
       "1  [0.057882732891363045, 0.04388163818948183, 0....   \n",
       "2  [0.025843460103289473, 0.022190718157910284, 0...   \n",
       "3  [0.0727303876705453, 0.05813604322334051, 0.04...   \n",
       "4  [0.06237074766339497, 0.0889687593086402, 0.14...   \n",
       "\n",
       "                                                  ir  filename  sequence  \n",
       "0  [0.011994992794439888, 0.01829167933971773, 0....  C-E-sT-Q  C-E-sT-Q  \n",
       "1  [0.019754579708913297, 0.015484649837671371, 0...    sS-G-V    sS-G-V  \n",
       "2  [0.06034964879213473, 0.04087290119317211, 0.0...     Y-G-W     Y-G-W  \n",
       "3  [0.02712906135457303, 0.01848644633855094, 0.0...    I-pT-A    I-pT-A  \n",
       "4  [0.010306055339872014, 0.016394710928848952, 0...    G-sS-C    G-sS-C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 site classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F-<mask>-M-Y-H'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def masking_seq(seq):\n",
    "    mask_id = -1\n",
    "    seq_list = seq.split('-')\n",
    "    for i, item in enumerate(seq_list):\n",
    "        if 's' in item or 'p' in item:\n",
    "            mask_id = i\n",
    "            break\n",
    "    if mask_id != -1:\n",
    "        masked_seq = seq_list[:]\n",
    "        masked_seq[mask_id] = '<mask>'\n",
    "        masked_seq = '-'.join(masked_seq)\n",
    "    else:\n",
    "        indices = []\n",
    "        target_chars = ['H', 'S', 'T', 'Y']\n",
    "        for char in target_chars:\n",
    "            for i, item in enumerate(seq_list):\n",
    "                if char in item and i not in indices:\n",
    "                    indices.append(i)\n",
    "                    break\n",
    "\n",
    "        mask_id = random.choice(indices)\n",
    "        masked_seq = seq_list.copy()\n",
    "        masked_seq[mask_id] = '<mask>'\n",
    "        return '-'.join(masked_seq)\n",
    "    \n",
    "    return masked_seq\n",
    "\n",
    "# 测试\n",
    "masking_seq('F-H-M-Y-H')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_spectra = test_df.raman.to_list()\n",
    "masked_sequence = [masking_seq(item) for item in test_df.sequence.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:07<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "\n",
    "all_pred_sequence = []\n",
    "correct, total = 0, 0\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequence, spectra):\n",
    "        self.sequence = sequence\n",
    "        self.spectra = spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequence[idx], self.spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        sequence, spectra = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(sequence), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "test_dataset = TestDataset(masked_sequence, masked_spectra)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_tokens_logits = model.infer_mlm(batch)\n",
    "    pred_tokens = torch.argmax(pred_tokens_logits, dim=-1)\n",
    "    \n",
    "    output = deepcopy(batch['smiles']['input_ids'])\n",
    "    mask = (batch['smiles']['input_ids'] == 4).cpu()\n",
    "    output[mask] = pred_tokens[mask]\n",
    "    \n",
    "    preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    all_pred_sequence.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7502986857825568\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_seq(tgt_seq, pred_seq):\n",
    "    tgt_seq = tgt_seq.replace('-', '')\n",
    "    if tgt_seq == pred_seq:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_seq':test_df['sequence'].to_list(), 'pred_seq':all_pred_sequence})\n",
    "df['top_1'] = df.apply(lambda row: check_seq(row['tgt_seq'], row['pred_seq']), axis=1)\n",
    "df['length'] = df.apply(lambda row: len(row['tgt_seq'].split('-')), axis=1)\n",
    "df['mod'] = df.apply(lambda row: 'phosphorylated' if 'p' in row['tgt_seq'] \n",
    "                             else 'sulfated' if 's' in row['tgt_seq'] \n",
    "                             else 'unmodified', axis=1)\n",
    "print(df.top_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.791612</td>\n",
       "      <td>3.858453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phosphorylation</th>\n",
       "      <td>0.749664</td>\n",
       "      <td>3.495289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulfation</th>\n",
       "      <td>0.719403</td>\n",
       "      <td>3.638806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    top_1    length\n",
       "mod                                \n",
       "negative         0.791612  3.858453\n",
       "phosphorylation  0.749664  3.495289\n",
       "sulfation        0.719403  3.638806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('mod').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lmdb\n",
    "import pickle\n",
    "from tqdm.auto import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_smiles):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_smiles = pred_smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_smiles[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_smiles = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'sequence': input_ids,  'spectra':spectra}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  8.15it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(test_df.raman.to_list(), test_df.sequence.to_list())\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "all_molecular_embeddings = []\n",
    "all_spectral_embeddings = []\n",
    "\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        \n",
    "        all_molecular_embeddings.append(molecular_embedding)\n",
    "        all_spectral_embeddings.append(spectral_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@1:0.65034\n",
      "recall@3:0.87774\n",
      "recall@5:0.92991\n",
      "recall@10:0.96655\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_recall(similarity_matrix, k, return_result=False):\n",
    "    num_queries = similarity_matrix.size(0)\n",
    "    _, topk_indices = similarity_matrix.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct_list = []\n",
    "    for i in range(num_queries):\n",
    "        if i in topk_indices[i]:\n",
    "            correct_list.append(1)\n",
    "        else:\n",
    "            correct_list.append(0)\n",
    "    recall_at_k = sum(correct_list) / num_queries\n",
    "    \n",
    "    print(f'recall@{k}:{recall_at_k:.5f}')\n",
    "    if return_result:\n",
    "        return correct_list\n",
    "\n",
    "all_molecular_embeddings = torch.cat(all_molecular_embeddings)\n",
    "all_spectral_embeddings = torch.cat(all_spectral_embeddings)\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(all_spectral_embeddings, all_molecular_embeddings)\n",
    "top1 = compute_recall(similarity_matrix, k=1, return_result=True)\n",
    "top3 = compute_recall(similarity_matrix, k=3, return_result=True)\n",
    "compute_recall(similarity_matrix, k=5, return_result=False)\n",
    "compute_recall(similarity_matrix, k=10, return_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38509/4173466750.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['top_1'] = top1\n",
      "/tmp/ipykernel_38509/4173466750.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['top_3'] = top3\n",
      "/tmp/ipykernel_38509/4173466750.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['mod'] = df.apply(lambda row: 'phosphorylation' if 'p' in row['sequence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.760157</td>\n",
       "      <td>0.930537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phosphorylation</th>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.865410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulfation</th>\n",
       "      <td>0.587065</td>\n",
       "      <td>0.846766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    top_1     top_3\n",
       "mod                                \n",
       "negative         0.760157  0.930537\n",
       "phosphorylation  0.623149  0.865410\n",
       "sulfation        0.587065  0.846766"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_df[:]\n",
    "df['top_1'] = top1\n",
    "df['top_3'] = top3\n",
    "df['mod'] = df.apply(lambda row: 'phosphorylated' if 'p' in row['sequence'] \n",
    "                             else 'sulfated' if 's' in row['sequence'] \n",
    "                             else 'unmodified', axis=1)\n",
    "df.groupby('mod').mean('top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 de novo generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 greddy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_sequences = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=6)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_sequences.extend(pred_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2524890481879729\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_seq(tgt_seq, pred_seq):\n",
    "    tgt_seq = tgt_seq.replace('-', '')\n",
    "    if tgt_seq == pred_seq:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_seq':test_df['sequence'].to_list(), 'pred_seq':all_pred_sequences})\n",
    "df['top_1'] = df.apply(lambda row: check_seq(row['tgt_seq'], row['pred_seq']), axis=1)\n",
    "print(df.top_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 beam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 10.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_sequence = []\n",
    "test_dataset = TestDataset(test_df['raman'].to_list())\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_sequence_ids_list = model.beam_infer_lm(batch, max_len=6, beam_size=10, temperature=17.5)['pred_ids']\n",
    "    for pred_sequence_ids in pred_sequence_ids_list:\n",
    "        pred_sequence = tokenizer.batch_decode(pred_sequence_ids)\n",
    "        pred_sequence = [item.split('</s>')[0].replace('<s>', '') for item in pred_sequence]\n",
    "        all_pred_sequence.append(pred_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.17483\n",
      "top-3:\t\t0.34090\n",
      "top-5:\t\t0.40064\n",
      "top-10:\t\t0.43011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def check_beam_seq(tgt_seq, pred_seq_list):\n",
    "    tgt_seq = tgt_seq.replace('-', '')\n",
    "    pred_mol_list = []\n",
    "    if tgt_seq in pred_seq_list:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df = pd.DataFrame({'tgt_seq':test_df['sequence'].to_list(), 'pred_seq':[list(dict.fromkeys(item)) for item in all_pred_sequence]})\n",
    "df['top_1'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:1]), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:3]), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:5]), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_seq(row['tgt_seq'], row['pred_seq'][:10]), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tgt_seq</th>\n",
       "      <th>pred_seq</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-E-sT-Q</td>\n",
       "      <td>[CPsTD, CPID, CDEsT, CsTsTD, CsTED, CPsTsT, CP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sS-G-V</td>\n",
       "      <td>[sSG, sSGV, sSVG, sSVM, sSGpH1, sSVP]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y-G-W</td>\n",
       "      <td>[WYW, WYG, WYY, WGY, YGW]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-pT-A</td>\n",
       "      <td>[VpTA, VpTI, TIA, VpTAF]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G-sS-C</td>\n",
       "      <td>[, sSGC, GsSC, WGC, sSsSC, WpSC]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tgt_seq                                           pred_seq  top_1  top_3  \\\n",
       "0  C-E-sT-Q  [CPsTD, CPID, CDEsT, CsTsTD, CsTED, CPsTsT, CP...      0      0   \n",
       "1    sS-G-V              [sSG, sSGV, sSVG, sSVM, sSGpH1, sSVP]      0      1   \n",
       "2     Y-G-W                          [WYW, WYG, WYY, WGY, YGW]      0      0   \n",
       "3    I-pT-A                           [VpTA, VpTI, TIA, VpTAF]      0      0   \n",
       "4    G-sS-C                   [, sSGC, GsSC, WGC, sSsSC, WpSC]      0      1   \n",
       "\n",
       "   top_5  top_10  \n",
       "0      0       0  \n",
       "1      1       1  \n",
       "2      1       1  \n",
       "3      0       0  \n",
       "4      1       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 rerank by retrieval module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sequence_list = [list(set(item)) for item in all_pred_sequence]\n",
    "candidate_spectra_list = [[test_df.iloc[i]['raman']] * len(item) for i, item in enumerate(candidate_sequence_list)]\n",
    "tgt_sequence_list = [[test_df.iloc[i]['sequence']] * len(item) for i, item in enumerate(candidate_sequence_list)]\n",
    "\n",
    "candidate_sequence_list = [subitem for item in candidate_sequence_list for subitem in item]\n",
    "candidate_spectra_list = [subitem for item in candidate_spectra_list for subitem in item]\n",
    "tgt_sequence_list = [subitem for item in tgt_sequence_list for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:31<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between predicted molecules and target spectra\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    if type(embedding_query) != torch.Tensor:\n",
    "        embedding_query = torch.tensor(embedding_query)\n",
    "    if type(embedding_key) != torch.Tensor:\n",
    "        embedding_key = torch.tensor(embedding_key)\n",
    "    \n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra, pred_sequence):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "        self.pred_sequence = pred_sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx], self.pred_sequence[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra, pred_sequence = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(pred_sequence), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'sequence': input_ids,  'spectra':spectra}\n",
    "\n",
    "    \n",
    "valid_sim_list = []\n",
    "\n",
    "test_dataset = TestDataset(candidate_spectra_list, candidate_sequence_list)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        molecular_embedding = model.get_molecular_embeddings(batch, use_cls_token=True)['proj_output']\n",
    "        spectral_embedding = model.get_spectral_embeddings(batch)['proj_output']\n",
    "        sim = calculate_similarity_matrix(spectral_embedding, molecular_embedding)\n",
    "    valid_sim_list += torch.diag(sim).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall@1:\t0.27997 \n",
      "recall@3:\t0.41179 \n",
      "recall@5:\t0.42732 \n",
      "recall@10:\t0.43011\n",
      "recall@100:\t0.43011\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tgt_sequence_list = [item.replace('-', '') for item in tgt_sequence_list]\n",
    "df = pd.DataFrame({'target_sequence':tgt_sequence_list, 'pred_sequence':candidate_sequence_list, 'similarity':valid_sim_list})\n",
    "\n",
    "df_sorted = df.sort_values(by=['target_sequence', 'similarity'], ascending=[True, False])\n",
    "\n",
    "df = df_sorted.groupby('target_sequence').agg({\n",
    "    'pred_sequence': lambda x: ','.join(x),\n",
    "    'similarity': lambda x: ','.join(map(str, x))\n",
    "}).reset_index()\n",
    "\n",
    "for top_k in [1, 3, 5, 10, 100]: \n",
    "    df[f'top_{top_k}_recall'] = df.apply(lambda row: row['target_sequence'].replace('-', '') in row['pred_sequence'].split(',')[:top_k], axis=1)\n",
    "\n",
    "df['rank'] = df.apply(lambda row: (row['pred_sequence'].split(',').index(row['target_sequence']))+1 if row['target_sequence'] in row['pred_sequence'].split(',') else 0, axis=1)\n",
    "df['mod'] = df.apply(lambda row: 'phosphorylated' if 'p' in row['target_sequence'] else ('sulfated' if 's' in row['target_sequence'] else 'unmodified'), axis=1)\n",
    "\n",
    "print(f\"\"\"\n",
    "recall@1:\\t{df.top_1_recall.mean():.5f} \n",
    "recall@3:\\t{df.top_3_recall.mean():.5f} \n",
    "recall@5:\\t{df.top_5_recall.mean():.5f} \n",
    "recall@10:\\t{df.top_10_recall.mean():.5f}\n",
    "recall@100:\\t{df.top_100_recall.mean():.5f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1_recall</th>\n",
       "      <th>top_3_recall</th>\n",
       "      <th>top_5_recall</th>\n",
       "      <th>top_10_recall</th>\n",
       "      <th>top_100_recall</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>0.272608</td>\n",
       "      <td>0.418087</td>\n",
       "      <td>0.435125</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.702490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phosphorylation</th>\n",
       "      <td>0.289367</td>\n",
       "      <td>0.413190</td>\n",
       "      <td>0.423957</td>\n",
       "      <td>0.425303</td>\n",
       "      <td>0.425303</td>\n",
       "      <td>0.621803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulfation</th>\n",
       "      <td>0.278607</td>\n",
       "      <td>0.405970</td>\n",
       "      <td>0.423881</td>\n",
       "      <td>0.426866</td>\n",
       "      <td>0.426866</td>\n",
       "      <td>0.654726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 top_1_recall  top_3_recall  top_5_recall  top_10_recall  \\\n",
       "mod                                                                        \n",
       "normal               0.272608      0.418087      0.435125       0.439056   \n",
       "phosphorylation      0.289367      0.413190      0.423957       0.425303   \n",
       "sulfation            0.278607      0.405970      0.423881       0.426866   \n",
       "\n",
       "                 top_100_recall      rank  \n",
       "mod                                        \n",
       "normal                 0.439056  0.702490  \n",
       "phosphorylation        0.425303  0.621803  \n",
       "sulfation              0.426866  0.654726  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('mod').mean('top_1_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
