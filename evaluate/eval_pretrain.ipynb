{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import build_model\n",
    "from models import BertModel, PretrainModel_CL, PretrainModel_MLM, PretrainModel_LM, PretrainModel_CL_MLM, PretrainModel_CL_LM, PretrainModel_ALL, PretrainModel_Phase \n",
    "from utils.base import seed_everything\n",
    "\n",
    "seed_everything(624)\n",
    "device = 'cpu'\n",
    "\n",
    "# model = build_model('bert_mlm').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/bert_mlm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_cl').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_cl.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_mlm').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_mlm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_lm').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_lm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_cl_mlm').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_cl_mlm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_cl_lm').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_cl_lm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "# model = build_model('vib2mol_all').to(device)\n",
    "# ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_cl_mlm_lm.pth', \n",
    "#                   map_location=device, weights_only=True)\n",
    "\n",
    "model = build_model('vib2mol_phase').to(device)\n",
    "ckpt = torch.load('../checkpoints/mols/raman-kekule_smiles/vib2mol_phase.pth', \n",
    "                  map_location=device, weights_only=True)\n",
    "\n",
    "\n",
    "ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}\n",
    "model.load_state_dict(ckpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Evaluate contrastive retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 417/417 [04:47<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import Dataloader\n",
    "from utils.collators import BaseCollator\n",
    "from utils.base import BaseEngine\n",
    "\n",
    "dataloader = Dataloader(lmdb_path='qm9', \n",
    "                            data_dir=f'../datasets/vibench', \n",
    "                            target_keys=['raman', 'kekule_smiles'], \n",
    "                            collate_fn=BaseCollator(spectral_types=['raman'],tokenizer_path=f'../models/MolTokenizer'), \n",
    "                            device=device)\n",
    "\n",
    "test_loader = dataloader.generate_dataloader(mode='test', batch_size=64)\n",
    "\n",
    "engine = BaseEngine(test_loader=test_loader, model=model, device=device, device_rank=0)\n",
    "out = engine.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@1:0.81508\n",
      "recall@3:0.96373\n",
      "recall@5:0.98168\n",
      "recall@10:0.99314\n",
      "recall@100:0.99951\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity_matrix(embedding_query, embedding_key):\n",
    "    embedding_query = F.normalize(embedding_query, p=2, dim=1)\n",
    "    embedding_key = F.normalize(embedding_key, p=2, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(embedding_query, embedding_key.t())\n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_recall(similarity_matrix, k, verbose=False):\n",
    "    num_queries = similarity_matrix.size(0)\n",
    "    _, topk_indices = similarity_matrix.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct = 0\n",
    "    for i in range(num_queries):\n",
    "        if i in topk_indices[i]:\n",
    "            correct += 1\n",
    "    recall_at_k = correct / num_queries\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'recall@{k}:{recall_at_k:.5f}')\n",
    "    else:\n",
    "        return recall_at_k\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(out['spectral_proj_output'], out['molecular_proj_output'])\n",
    "compute_recall(similarity_matrix, k=1, verbose=True)\n",
    "compute_recall(similarity_matrix, k=3, verbose=True)\n",
    "compute_recall(similarity_matrix, k=5, verbose=True)\n",
    "compute_recall(similarity_matrix, k=10, verbose=True)\n",
    "compute_recall(similarity_matrix, k=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26687, 26687])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/1j/7pqn40651hvgyt1913gz84880000gn/T/ipykernel_38066/2696500837.py:16: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  test_df = pd.DataFrame([pickle.loads(item[1]) for item in test_data])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import lmdb\n",
    "import pickle\n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "db = lmdb.open('../datasets/vibench/qm9/qm9_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())\n",
    "\n",
    "test_df = pd.DataFrame([pickle.loads(item[1]) for item in test_data])\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/MolTokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C(=O)O NC1(<mask><mask><mask><mask><mask><mask>)CC1C1=CC=CC=C1\n",
      "=O NC1(C(<mask><mask>)O)CC1C1=CC=CC=C1\n"
     ]
    }
   ],
   "source": [
    "def extract_branches(s):\n",
    "    result = []\n",
    "    stack = []\n",
    "    start = -1\n",
    "    \n",
    "    for i, char in enumerate(s):\n",
    "        if char == '(':\n",
    "            if not stack:\n",
    "                start = i\n",
    "            stack.append(i)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    result.append(s[start+1:i])\n",
    "                    extract_nested = extract_branches(s[start+1:i])\n",
    "                    result.extend(extract_nested)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# test\n",
    "test_string = \"NC1(C(=O)O)CC1C1=CC=CC=C1\"\n",
    "branches = extract_branches(test_string)\n",
    "for branch in branches:\n",
    "    masked_input = test_string.replace(branch, '<mask>'*len(branch))\n",
    "    print(branch, masked_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate molecular accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26687/26687 [00:00<00:00, 73311.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20966 20966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_smiles = []\n",
    "masked_smiles = []\n",
    "masked_spectra = []\n",
    "branches_list = []\n",
    "masked_smi_dict = {}\n",
    "\n",
    "mask_prob = None\n",
    "for smi, spec in tqdm(zip(test_df['kekule_smiles'].to_list(), test_df['raman'].to_list()), total=len(test_df)):\n",
    "    branches = extract_branches(smi)\n",
    "    for branch in branches:\n",
    "        if mask_prob is None or (len(smi) * mask_prob < len(branch) and len(branch) <= len(smi) * (mask_prob + 0.15)):\n",
    "            len_token = len(tokenizer(branch)['input_ids'])-2\n",
    "            masked_smi = smi.replace(f\"({branch})\", f\"({'<mask>'*len_token})\")\n",
    "            if masked_smi not in masked_smi_dict:\n",
    "                branches_list.append(branch)\n",
    "                masked_smi_dict[masked_smi] = 1\n",
    "                masked_smiles.append(masked_smi)\n",
    "                masked_spectra.append(spec)\n",
    "                raw_smiles.append(smi)\n",
    "\n",
    "print(len(raw_smiles), len(branches_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "all_pred_smiles = []\n",
    "correct, total = 0, 0\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, smiles, spectra):\n",
    "        self.smiles = smiles\n",
    "        self.spectra = spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.smiles[idx], self.spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        smiles, spectra = zip(*batch)\n",
    "        spectra = torch.as_tensor(np.array(spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        input_ids = self.tokenizer(list(smiles), return_tensors='pt', padding='max_length', max_length=256, truncation=True)\n",
    "        input_ids = {'input_ids':input_ids['input_ids'].to(device), 'attention_mask':input_ids['attention_mask'].to(device)}\n",
    "        return {'smiles': input_ids,  'spectra':spectra}\n",
    "\n",
    "test_dataset = TestDataset(masked_smiles, masked_spectra)\n",
    "test_collator = TestCollator(tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_tokens_logits = model.infer_mlm(batch)\n",
    "    pred_tokens = torch.argmax(pred_tokens_logits, dim=-1)\n",
    "    \n",
    "    output = batch['smiles']['input_ids'][:]\n",
    "    mask = (batch['smiles']['input_ids'] == 4).cpu()\n",
    "    output[mask] = pred_tokens[mask]\n",
    "    \n",
    "    preds = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    all_pred_smiles.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37100/37100 [00:07<00:00, 5078.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "tgt_fgs = []\n",
    "pred_fgs = []\n",
    "tgt_total_counter = {}\n",
    "tgt_correct_counter = {}\n",
    "\n",
    "for i in trange(len(raw_smiles)):\n",
    "\n",
    "    masked_fg = np.array(tokenizer(masked_smiles[i])['input_ids'])\n",
    "    tgt_fg = np.array(tokenizer(raw_smiles[i])['input_ids'])\n",
    "    pred_fg = np.array(tokenizer(all_pred_smiles[i])['input_ids'])[:len(masked_fg)]\n",
    "\n",
    "    # 找出所有mask的索引\n",
    "    indices_of_mask = np.where(masked_fg == 4)[0]\n",
    "\n",
    "    # 找出所有连续mask的索引\n",
    "    consecutive_indices = []\n",
    "    current_list = []\n",
    "\n",
    "    for i in range(len(indices_of_mask)):\n",
    "        if i == 0 or indices_of_mask[i] == indices_of_mask[i - 1] + 1:\n",
    "            current_list.append(indices_of_mask[i])\n",
    "        else:\n",
    "            if current_list:\n",
    "                consecutive_indices.append(current_list)\n",
    "            current_list = [indices_of_mask[i]]\n",
    "    if current_list:\n",
    "        consecutive_indices.append(current_list)\n",
    "\n",
    "    for mask in consecutive_indices:\n",
    "        if len(mask) == 1: mask = mask[0]\n",
    "        tgt_fg_str = tokenizer.decode(tgt_fg[mask])\n",
    "        pred_fg_str = tokenizer.decode(pred_fg[mask])\n",
    "        tgt_fgs.append(tgt_fg_str)\n",
    "        pred_fgs.append(pred_fg_str)\n",
    "\n",
    "        if tgt_fg_str in tgt_total_counter:\n",
    "            tgt_total_counter[tgt_fg_str] += 1\n",
    "        else:\n",
    "            tgt_total_counter[tgt_fg_str] = 1\n",
    "        if pred_fg_str == tgt_fg_str and pred_fg_str not in tgt_correct_counter:\n",
    "            tgt_correct_counter[tgt_fg_str] = 1\n",
    "        elif pred_fg_str == tgt_fg_str and pred_fg_str  in tgt_correct_counter:\n",
    "            tgt_correct_counter[tgt_fg_str] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique: 1744 | total: 41334 | correct: 38390.0 | accuracy: 0.9287753423331881\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'fg':tgt_total_counter.keys(), 'count':tgt_total_counter.values()})\n",
    "df2 = pd.DataFrame({'fg':tgt_correct_counter.keys(), 'correct':tgt_correct_counter.values()})\n",
    "df = pd.merge(df1, df2, on='fg', how='left')\n",
    "df[df.isna()] = 0\n",
    "df['accuracy'] = df['correct'] / df['count']\n",
    "print(f\"unique: {len(df)} | total: {df['count'].sum()} | correct: {df['correct'].sum()} | accuracy: {df['correct'].sum() / df['count'].sum()}\")\n",
    "\n",
    "df.sort_values('count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 spectrum-guided casual decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "# Open LMDB \n",
    "db = lmdb.open('../datasets/vibench/zinc15/zinc15_test.lmdb', subdir=False, lock=False, map_size=int(1e11))\n",
    "\n",
    "# Open a transaction and perform a read operation\n",
    "with db.begin() as txn:\n",
    "    test_data = list(txn.cursor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 10883/10883 [00:00<00:00, 74187.15it/s]\n",
      "100%|██████████| 10883/10883 [00:00<00:00, 33787.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len:102\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import multiprocessing as mp \n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "smiles = [pickle.loads(item[1])['kekule_smiles'] for item in tqdm(test_data)]\n",
    "spectra = [pickle.loads(item[1])['raman'] for item in tqdm(test_data)]\n",
    "# filenames = [pickle.loads(item[1])['filename'] for item in tqdm(test_data)]\n",
    "\n",
    "length = [len(item) for item in smiles]\n",
    "max_len = max(length)+2\n",
    "print(f'max_len:{max_len}')\n",
    "    \n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/MolTokenizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 greedy generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [01:38<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(spectra)\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids = model.infer_lm(batch, max_len=max_len)['pred_ids']\n",
    "    pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "    pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "    all_pred_smiles.extend(pred_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "res_smiles = []\n",
    "for item in all_pred_smiles:\n",
    "    tmp_mol = Chem.MolFromSmiles(item)\n",
    "    if tmp_mol is not None:\n",
    "        tmp_smiles = Chem.MolToSmiles(tmp_mol, isomericSmiles=False, kekuleSmiles=True, canonical=True)\n",
    "    else:\n",
    "        tmp_smiles = '*'\n",
    "    res_smiles.append(tmp_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "\n",
    "def check_mols(pred_smiles, tgt_smiles):\n",
    "    pred_mol = Chem.MolFromSmiles(pred_smiles)\n",
    "    tgt_mol = Chem.MolFromSmiles(tgt_smiles)\n",
    "    if pred_mol is not None and tgt_mol is not None:\n",
    "        if Chem.MolToInchiKey(pred_mol) == Chem.MolToInchiKey(tgt_mol):\n",
    "            return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26687/26687 [00:00<00:00, 73987.25it/s]\n",
      "100%|██████████| 26687/26687 [00:12<00:00, 2107.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6289579195863154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>tgt</th>\n",
       "      <th>filename</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCC12CC1OC2=N</td>\n",
       "      <td>COCC12CC1OC2=N</td>\n",
       "      <td>dsgdb9nsd_119549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C1C2COC1(CO)C2</td>\n",
       "      <td>O=C1C2COC1(CO)C2</td>\n",
       "      <td>dsgdb9nsd_106611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCC1C(O)C1O</td>\n",
       "      <td>OCC1C(O)C1O</td>\n",
       "      <td>dsgdb9nsd_003107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1C(=N)OC2CC21O</td>\n",
       "      <td>CC1C(=N)OC2CC21O</td>\n",
       "      <td>dsgdb9nsd_075828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1OC(C)(C)C1C=O</td>\n",
       "      <td>CC1OC(C)C1(C)C=O</td>\n",
       "      <td>dsgdb9nsd_086297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred               tgt          filename  correct\n",
       "0    COCC12CC1OC2=N    COCC12CC1OC2=N  dsgdb9nsd_119549        1\n",
       "1  O=C1C2COC1(CO)C2  O=C1C2COC1(CO)C2  dsgdb9nsd_106611        1\n",
       "2       OCC1C(O)C1O       OCC1C(O)C1O  dsgdb9nsd_003107        1\n",
       "3  CC1C(=N)OC2CC21O  CC1C(=N)OC2CC21O  dsgdb9nsd_075828        1\n",
       "4  CC1OC(C)(C)C1C=O  CC1OC(C)C1(C)C=O  dsgdb9nsd_086297        0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filenames = [pickle.loads(item[1])['filename'] for item in tqdm(test_data)]\n",
    "df = pd.DataFrame({'pred':res_smiles, 'tgt':smiles, 'filename':filenames, 'correct':[check_mols(res_smiles[i], smiles[i]) for i in trange(len(res_smiles))]})\n",
    "print(df.correct.mean())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6289579195863154 nan\n"
     ]
    }
   ],
   "source": [
    "print(df[df.filename.str.startswith('d')].correct.mean(),\n",
    "df[df.filename.str.startswith('Z')].correct.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [19:41<00:00, 13.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tgt_spectra):\n",
    "        self.tgt_spectra = tgt_spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tgt_spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tgt_spectra[idx]\n",
    "\n",
    "class TestCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        tgt_spectra = batch\n",
    "        spectra = torch.as_tensor(np.array(tgt_spectra), dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        return {'spectra':spectra}\n",
    "\n",
    "beam_size = 10\n",
    "\n",
    "all_pred_smiles = []\n",
    "test_dataset = TestDataset(spectra[:])\n",
    "test_collator = TestCollator()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, collate_fn=test_collator)\n",
    "test_bar = tqdm(test_loader)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_bar:\n",
    "    with torch.no_grad():\n",
    "        pred_smiles_ids_list = model.beam_infer_lm(batch, max_len=max_len, beam_size=beam_size, temperature=3.5)['pred_ids']\n",
    "    for pred_smiles_ids in pred_smiles_ids_list:\n",
    "        pred_smiles = tokenizer.batch_decode(pred_smiles_ids)\n",
    "        pred_smiles = [item.split('</s>')[0].replace('<s>', '') for item in pred_smiles]\n",
    "        all_pred_smiles.append(pred_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank by beam score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import trange\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def check_beam_mols(pred_smiles_list, tgt_smiles):\n",
    "    pred_mol_list = []\n",
    "    for item in pred_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(item)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                inchi_key = Chem.MolToInchiKey(mol)\n",
    "                pred_mol_list.append(inchi_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {item}: {e}\")\n",
    "                pred_mol_list.append('')\n",
    "        else:\n",
    "            pred_mol_list.append('')\n",
    "    tgt_mol = Chem.MolToInchiKey(Chem.MolFromSmiles(tgt_smiles))\n",
    "    if tgt_mol in pred_mol_list:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1:\t\t0.49858\n",
      "top-3:\t\t0.58835\n",
      "top-5:\t\t0.59809\n",
      "top-10:\t\t0.59901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.DataFrame({'tgt_smiles':smiles, 'pred_smiles':[list(dict.fromkeys(item)) for item in all_pred_smiles]})\n",
    "df['top_1'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:1], row['tgt_smiles']), axis=1)\n",
    "df['top_3'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:3], row['tgt_smiles']), axis=1)\n",
    "df['top_5'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:5], row['tgt_smiles']), axis=1)\n",
    "df['top_10'] = df.apply(lambda row: check_beam_mols(row['pred_smiles'][:10], row['tgt_smiles']), axis=1)\n",
    "\n",
    "print(f'top-1:\\t\\t{df.top_1.mean():.5f}\\ntop-3:\\t\\t{df.top_3.mean():.5f}\\ntop-5:\\t\\t{df.top_5.mean():.5f}\\ntop-10:\\t\\t{df.top_10.mean():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
